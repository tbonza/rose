{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this notebook to write your code for assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import string\n",
    "import time\n",
    "import unidecode\n",
    "import random\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters\n",
    "\n",
    "Scavenger hunts are fun but I like putting my hyperparameters in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL_CHARACTERS = ' abcdefghijklmnopqrstuvwxyz'\n",
    "ALL_CHARACTERS = string.printable\n",
    "HP = {\n",
    "    \n",
    "    # Data pre-processing\n",
    "    \n",
    "    \"all_chars\": ALL_CHARACTERS,\n",
    "    \"char_set\": set(ALL_CHARACTERS),\n",
    "    \"random_seed\": 42,\n",
    "    \"n_chars\": 0, # will need to update\n",
    "    \"chunk_len\": 40,\n",
    "    \n",
    "    # Training model\n",
    "    \n",
    "    \"n_epochs\": 2000,\n",
    "    \"hidden_size\": 100,\n",
    "    \"n_layers\": 1,\n",
    "    \"lr\": 0.005,\n",
    "    \"temperature\": 0.8,\n",
    "    \"prime_str\": \"a\",\n",
    "    \"predict_len\": 100,\n",
    "    \n",
    "    # Model reporting\n",
    "    \n",
    "    \"print_every\": 100,\n",
    "    \"plot_every\": 10,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing data\n",
    "\n",
    "Read the data file of `shakespeare.txt` and prepare the inputs/outputs to your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    chars = list(HP[\"char_set\"])\n",
    "    lines = []\n",
    "    for line in data:\n",
    "        line = ''.join([i for i in line.lower().strip() if i in chars])\n",
    "        if len(line) > 0:\n",
    "            lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_chunk():\n",
    "    random.seed(HP[\"random_seed\"])\n",
    "    start_index = random.randint(0, HP[\"n_chars\"] - HP[\"chunk_len\"])\n",
    "    end_index = start_index + HP[\"chunk_len\"] + 1\n",
    "    return FILE[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = HP[\"all_chars\"].index(string[c])\n",
    "    return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/shakespeare.txt\", \"r\") as infile:\n",
    "    data = infile.readlines()\n",
    "    \n",
    "data = clean_data(data)\n",
    "FILE = ''.join(data)\n",
    "HP['n_chars'] = len(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 91873 total characters and 100 unique characters in your data.\n",
      "\n",
      "Example file chunk: '1from fairest creatures we desire increa'\n"
     ]
    }
   ],
   "source": [
    "print('There are %d total characters and %d unique characters in your data.' % (HP['n_chars'], len(HP['char_set'])))\n",
    "\n",
    "print(\"\\nExample file chunk: '{}'\".format(FILE[:HP['chunk_len']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random chunk:\n",
      "of view is pleased to dote.nor are mine c\n",
      "\n",
      "Transforms to char tensor:\n",
      "tensor([24, 15, 94, 31, 18, 14, 32, 94, 18, 28, 94, 25, 21, 14, 10, 28, 14, 13,\n",
      "        94, 29, 24, 94, 13, 24, 29, 14, 75, 23, 24, 27, 94, 10, 27, 14, 94, 22,\n",
      "        18, 23, 14, 94, 12])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rchunk = random_chunk()\n",
    "rutens = char_tensor(rchunk)\n",
    "\n",
    "print(\"Random chunk:\\n{}\\n\\nTransforms to char tensor:\\n{}\\n\".format(rchunk, rutens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Model\n",
    "\n",
    "Implement a character-based LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(HP['chunk_len']):\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        label = target[c]\n",
    "        label = label.unsqueeze(0)\n",
    "        loss += criterion(output, label)\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data.item() / HP['chunk_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prime_str='a', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden()\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1).item()\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = HP['all_chars'][top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3m 48s (100 5%) 0.0671]\n",
      "Whw to dote.nor are mine is dote.nor are cor are mine ce.nor are mine co dote.nor are ce.nor are mine  \n",
      "\n",
      "[7m 40s (200 10%) 0.0130]\n",
      "Whd to dote.nor are mine cor are mine ce.nor are mine ce.nor are mine co doto dote.nor are mine co dot \n",
      "\n",
      "[11m 24s (300 15%) 0.0063]\n",
      "Wh are mine co dote.nor are mine co dote.nor are mine co dote.nor are mine co dote.nor are mine ce.nor \n",
      "\n",
      "[15m 17s (400 20%) 0.0039]\n",
      "Wh view is pleased to dote.nor are mine co dote.nor are mine co dote.nor are mine ce.nor are mine co d \n",
      "\n",
      "[19m 7s (500 25%) 0.0027]\n",
      "Wh co dote.nor are mind to dote.nor are mine co dote.nor are mine ce.nor are mine co dote.nor are mine \n",
      "\n",
      "[22m 53s (600 30%) 0.0020]\n",
      "Wh view is pleased to dote.nor are mine co dote.nor are mine co dote.nor are mine ce.nor are mine ce.n \n",
      "\n",
      "[26m 48s (700 35%) 0.0016]\n",
      "Wh mine co dote.nor are mine ce.nor are mine co are mine co dote.nor are mine co dote.nor are mine co  \n",
      "\n",
      "[30m 37s (800 40%) 0.0013]\n",
      "Wh dote.nor are mine co dote.nor are mine co dote.nor are mine co dote.nor are mine co dote.nor are mi \n",
      "\n",
      "[34m 24s (900 45%) 0.0010]\n",
      "Wh view is pleased to dote.nor are mine co dote.nor are mine co dote.nor are mine co dote.nor are mine \n",
      "\n",
      "[38m 19s (1000 50%) 0.0009]\n",
      "Wh view is pleased to dote.nor are mine ce.nor are mine ce.nor are mine co dote.nor are mine co dote.n \n",
      "\n",
      "[42m 5s (1100 55%) 0.0007]\n",
      "Whased to dote.nor are mine co dote.nor are mine co dote.nor are mine co dote.nor are mine co dote.nor \n",
      "\n",
      "[45m 55s (1200 60%) 0.0006]\n",
      "Wh view is pleased to dote.nor are mine co dote.nor are mine co dote.nor are mine co dote.nor are mine \n",
      "\n",
      "[49m 48s (1300 65%) 0.0006]\n",
      "Wh co dote.nor are mine co dote.nor are mine co dote.nor are mine co dote.nor are mine co dote.nor are \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "decoder = RNN(HP['n_chars'], HP['hidden_size'], HP['n_chars'], HP['n_layers'])\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=HP['lr'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, HP['n_epochs'] + 1):\n",
    "    loss = train(*random_training_set())       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % HP['print_every'] == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / HP['n_epochs'] * 100, loss))\n",
    "        print(evaluate('Wh', HP[\"predict_len\"]), '\\n')\n",
    "\n",
    "    if epoch % HP['plot_every'] == 0:\n",
    "        all_losses.append(loss_avg / HP['plot_every'])\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Training Losses\n",
    "\n",
    "Plotting the historical loss during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating at different \"temperatures\"\n",
    "\n",
    "Changing the `temperature` argument (variance) for 1.5, 0.75. 0.25 and sample outputs from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7m 35s (200 10%) 0.0181]\n",
      "Whs pleased to dote.nor are mine cne ce ciew is pleased to dote.nor are mine ciew is pleased to dote.n \n",
      "\n",
      "[11m 24s (300 15%) 0.0088]\n",
      "Whw is pleased to dote.nor are mine cis pleased to dote.nor are mine ciew is pleased te.nor are mine c \n",
      "\n",
      "[15m 16s (400 20%) 0.0054]\n",
      "Wh view is pleased to dote.nor are mine ciew is pleased to dote.nor are mine ciew is pleased to dote.n \n",
      "\n",
      "[19m 2s (500 25%) 0.0038]\n",
      "Whs pleased to dote.nor are mine ce ciew is pleased to dote.nor are mine ciew is pleased to dote.nor a \n",
      "\n",
      "[22m 52s (600 30%) 0.0028]\n",
      "Wh mine ciew is pleased to dote.nor are mine ciew is pleased to dote.nor are mine ciew is pleased to d \n",
      "\n",
      "[26m 45s (700 35%) 0.0021]\n",
      "Whew is pleased to dote.nor are mine ce ciew is pleased to dote.nor are mine cne ciew is pleased to do \n",
      "\n",
      "[30m 31s (800 40%) 0.0017]\n",
      "Whe mine ciew is pleased to dote.nor are mine ciew is pleased to dote.nor are mine ce ciew is pleased  \n",
      "\n",
      "[34m 23s (900 45%) 0.0014]\n",
      "Wh view is pleased to dote.nor are mine ciew is pleased to dote.nor are mine ce ciew is pleased to dot \n",
      "\n",
      "[38m 14s (1000 50%) 0.0012]\n",
      "Whew is pleased to dote.nor are mine ciew is pleased to dote.nor are mine ciew is pleased to dote.nor  \n",
      "\n",
      "[42m 1s (1100 55%) 0.0010]\n",
      "Whew is pleased to dote.nor are mine c ciew is pleased to dote.nor are mine ce ciew is pleased to dote \n",
      "\n",
      "[45m 56s (1200 60%) 0.0008]\n",
      "Whs pleased to dote.nor are mine cre mine ciew is pleased to dote.nor are mine ciew is pleased to dote \n",
      "\n",
      "[49m 45s (1300 65%) 0.0007]\n",
      "Whs pleased to dote.nor are mine ce ciew is pleased to dote.nor are mine ciew is pleased to dote.nor a \n",
      "\n",
      "[53m 34s (1400 70%) 0.0006]\n",
      "Whew is pleased to dote.nor are mine ce ciew is pleased to dote.nor are mine ciew is pleased to dote.n \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ad3ef6fd035e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_epochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrandom_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss_avg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-f08ec7c178a5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(inp, target)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "temps = [1.5, 0.75, 0.25]\n",
    "\n",
    "for temp in temps:\n",
    "    print(\"Temperature: {}\".format(temp))\n",
    "    \n",
    "    decoder = RNN(HP['n_chars'], HP['hidden_size'], HP['n_chars'], HP['n_layers'])\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=HP['lr'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    start = time.time()\n",
    "    all_losses = []\n",
    "    loss_avg = 0\n",
    "\n",
    "    for epoch in range(1, HP['n_epochs'] + 1):\n",
    "        loss = train(*random_training_set())       \n",
    "        loss_avg += loss\n",
    "\n",
    "        if epoch % HP['print_every'] == 0:\n",
    "            print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / HP['n_epochs'] * 100, loss))\n",
    "            print(evaluate('Wh', HP[\"predict_len\"]), '\\n')\n",
    "\n",
    "        if epoch % HP['plot_every'] == 0:\n",
    "            all_losses.append(loss_avg / HP['plot_every'])\n",
    "            loss_avg = 0\n",
    "            \n",
    "            \n",
    "    plt.figure()\n",
    "    plt.plot(all_losses)\n",
    "    print(\"\\nTrained model with temp '{}'\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
