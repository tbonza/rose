{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this notebook to write your code for assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import string\n",
    "import time\n",
    "import unidecode\n",
    "import random\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters\n",
    "\n",
    "Scavenger hunts are fun but I like putting my hyperparameters in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_CHARACTERS = ' abcdefghijklmnopqrstuvwxyz'\n",
    "HP = {\n",
    "    \n",
    "    # Data pre-processing\n",
    "    \n",
    "    \"all_chars\": ALL_CHARACTERS,\n",
    "    \"char_set\": set(ALL_CHARACTERS),\n",
    "    \"random_seed\": 42,\n",
    "    \"n_chars\": 0, # will need to update\n",
    "    \"chunk_len\": 40,\n",
    "    \n",
    "    # Training model\n",
    "    \n",
    "    \"n_epochs\": 2000,\n",
    "    \"hidden_size\": 100,\n",
    "    \"n_layers\": 1,\n",
    "    \"lr\": 0.005,\n",
    "    \"temperature\": 0.8,\n",
    "    \"prime_str\": \"A\",\n",
    "    \"predict_len\": 100,\n",
    "    \n",
    "    # Model reporting\n",
    "    \n",
    "    \"print_every\": 100,\n",
    "    \"plot_every\": 10,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing data\n",
    "\n",
    "Read the data file of `shakespeare.txt` and prepare the inputs/outputs to your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    chars = list(HP[\"char_set\"])\n",
    "    lines = []\n",
    "    for line in data:\n",
    "        line = ''.join([i for i in line.lower().strip() if i in chars])\n",
    "        if len(line) > 0:\n",
    "            lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_chunk():\n",
    "    random.seed(HP[\"random_seed\"])\n",
    "    start_index = random.randint(0, HP[\"n_chars\"] - HP[\"chunk_len\"])\n",
    "    end_index = start_index + HP[\"chunk_len\"] + 1\n",
    "    return FILE[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = HP[\"all_chars\"].index(string[c])\n",
    "    return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/shakespeare.txt\", \"r\") as infile:\n",
    "    data = infile.readlines()\n",
    "    \n",
    "data = clean_data(data)\n",
    "FILE = ''.join(data)\n",
    "HP['n_chars'] = len(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 88382 total characters and 27 unique characters in your data.\n",
      "\n",
      "Example file chunk: 'from fairest creatures we desire increas'\n"
     ]
    }
   ],
   "source": [
    "print('There are %d total characters and %d unique characters in your data.' % (HP['n_chars'], len(HP['char_set'])))\n",
    "\n",
    "print(\"\\nExample file chunk: '{}'\".format(FILE[:HP['chunk_len']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random chunk:\n",
      "e dying thenmy love is as a fever longing\n",
      "\n",
      "Transforms to char tensor:\n",
      "tensor([ 5,  0,  4, 25,  9, 14,  7,  0, 20,  8,  5, 14, 13, 25,  0, 12, 15, 22,\n",
      "         5,  0,  9, 19,  0,  1, 19,  0,  1,  0,  6,  5, 22,  5, 18,  0, 12, 15,\n",
      "        14,  7,  9, 14,  7])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rchunk = random_chunk()\n",
    "rutens = char_tensor(rchunk)\n",
    "\n",
    "print(\"Random chunk:\\n{}\\n\\nTransforms to char tensor:\\n{}\\n\".format(rchunk, rutens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Model\n",
    "\n",
    "Implement a character-based LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(HP['chunk_len']):\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        label = target[c]\n",
    "        label = label.unsqueeze(0)\n",
    "        loss += criterion(output, label)\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data.item() / HP['chunk_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prime_str='a', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden()\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = HP['all_chars'][top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3m 20s (100 5%) 0.0494]\n",
      "whe dying thenmy love is as as a feve is as a fever as a fever longing thenmy love is as a fever longi \n",
      "\n",
      "[6m 42s (200 10%) 0.0099]\n",
      "whe dying thenmy love is as a fever longing thenmy love is as a fever longing thenmy love is as a feve \n",
      "\n",
      "[10m 5s (300 15%) 0.0047]\n",
      "whenmy love is as a fever longing thenmy love is as a fever longing thenmy love is as a fever longing  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "decoder = RNN(HP['n_chars'], HP['hidden_size'], HP['n_chars'], HP['n_layers'])\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=HP['lr'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, HP['n_epochs'] + 1):\n",
    "    loss = train(*random_training_set())       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % HP['print_every'] == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / HP['n_epochs'] * 100, loss))\n",
    "        print(evaluate('wh', 100), '\\n')\n",
    "\n",
    "    if epoch % HP['plot_every'] == 0:\n",
    "        all_losses.append(loss_avg / HP['plot_every'])\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Training Losses\n",
    "\n",
    "Plotting the historical loss during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating at different \"temperatures\"\n",
    "\n",
    "Changing the `temperature` argument (variance) for 1.5, 0.75. 0.25 and sample outputs from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
